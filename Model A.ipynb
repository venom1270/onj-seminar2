{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#java -mx3g -cp \"C:\\Users\\zigsi\\Desktop\\CoreNLP\\stanford-corenlp-full-2018-10-05/*\" edu.stanford.nlp.naturalli.OpenIE text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just the thought of leaving Earth both thrilled and terrified her. Her heart stopped as the trailer-sized shuttle moved forward on the track without making a sound. She took in a deep breath. she said, trying to be brave\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data/Weightless_dataset_train_A.csv\", \"r\", encoding=\"utf-8\")\n",
    "first = True\n",
    "questions = []\n",
    "answers = []\n",
    "grades = []\n",
    "texts = []\n",
    "for line in f:\n",
    "    if first:\n",
    "        first = False\n",
    "        continue\n",
    "    s = line.split(\";\")\n",
    "    questions.append(s[10])\n",
    "    answers.append(s[11])\n",
    "    grades.append(s[14])\n",
    "    texts.append(s[15])\n",
    "    \n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test data (first question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/Weightless_dataset_train.csv\", \"r\", encoding=\"utf8\")\n",
    "\n",
    "from nltk.sem import \n",
    "\n",
    "first = True\n",
    "questions_all = []\n",
    "answers_all = []\n",
    "grades_all = []\n",
    "texts_all = []\n",
    "for line in f:\n",
    "    if first:\n",
    "        first = False\n",
    "        continue\n",
    "    s = line.split(\";\")\n",
    "    questions_all.append(s[10])\n",
    "    answers_all.append(s[11])\n",
    "    grades_all.append(s[14])\n",
    "    texts_all.append(s[15])\n",
    "test_answers = [answers_all[i] for i in range(len(questions_all)) if questions_all[i] == questions[0]]\n",
    "test_grades = [float(grades_all[i].replace(\",\", \".\")) for i in range(len(questions_all)) if questions_all[i] == questions[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def getTokens(text):\n",
    "    lowered = text.lower()\n",
    "    table = text.maketrans({key: None for key in string.punctuation})\n",
    "    lowered = lowered.translate(table)\n",
    "    return nltk.word_tokenize(lowered)\n",
    "\n",
    "def preporcess(text):\n",
    "    tokens = getTokens(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(lemmas)\n",
    "    #pos_tag = nltk.pos_tag(lemmas)\n",
    "    #print(pos_tag)\n",
    "    #return \" \".join([pt[0] for pt in pos_tag if pt[1] == \"NN\" or pt[1][0:2] == \"VB\" or pt[1] == \"JJ\"])\n",
    "\n",
    "\n",
    "pre_answer = preporcess(answers[0])\n",
    "pre_text = preporcess(texts[0])\n",
    "#print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer() # parameters for tokenization, stopwords can be passed\n",
    "#tfidf = vect.fit_transform([texts[0], answers[0]])\n",
    "tfidf = vect.fit_transform([pre_answer, pre_text])\n",
    "cosine = (tfidf * tfidf.T).A\n",
    "#print(\"Cosine similarity between the documents: \\n{}\".format(cosine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  44 / 81\n"
     ]
    }
   ],
   "source": [
    "#weights = vect.transform(test_answers)\n",
    "weights = vect.transform([preporcess(a) for a in test_answers])\n",
    "predict = tfidf * weights.T\n",
    "correct = 0\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(predict.shape[1]):\n",
    "    p = 0\n",
    "    prediction = max(predict[0,i], predict[1,i])\n",
    "    if prediction > 0.3: #0.5\n",
    "        p = 1\n",
    "    elif prediction > 0.2: #0.3\n",
    "        p = 0.5\n",
    "    else:\n",
    "        p = 0\n",
    "    #print(\"Real grade: \", test_grades[i], \"Predicted grade: \", p)\n",
    "    if abs(p - test_grades[i]) <= 0:\n",
    "        correct += 1\n",
    "    if p == test_grades[i]:\n",
    "        #correct += 1\n",
    "        if p == 1 or p == 0.5:\n",
    "            TP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "    else:\n",
    "        if p == 1 or p == 0.5:\n",
    "            FP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "print(\"Correct: \", correct, \"/\", predict.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[texts[0] + answers[0]] 0.3 0.2 -> 38/81 correct\n",
    "\n",
    "[texts[0], answers[0]]  0.3 0.2 -> 42/81 correct "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy:  44 / 81  =  0.5432098765432098\n",
      "Precision:  43 / 73  =  0.589041095890411\n",
      "Recall:  43 / 50  =  0.86\n",
      "F1:  1.0131506849315068 / 1.449041095890411  =  0.6991869918699187\n"
     ]
    }
   ],
   "source": [
    "T = TP + TN\n",
    "A = T + FP + FN\n",
    "P = TP/(TP+FP)\n",
    "R = TP/(TP+FN)\n",
    "F1 = 2*P*R/(P+R)\n",
    "print(\"Classification Accuracy: \", T, \"/\", A, \" = \", T/A)\n",
    "print(\"Precision: \", TP, \"/\", TP+FP, \" = \", P)\n",
    "print(\"Recall: \", TP, \"/\", TP+FN, \" = \", TP/(TP+FN))\n",
    "print(\"F1: \", 2*P*R, \"/\", P+R, \" = \", F1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** WITHOUT p == 0.5 **\n",
    "Classification Accuracy:  42 / 81  =  0.5185185185185185\n",
    "Precision:  30 / 54  =  0.5555555555555556\n",
    "Recall:  30 / 45  =  0.6666666666666666\n",
    "F1:  0.7407407407407407 / 1.2222222222222223  =  0.606060606060606\n",
    "\n",
    "** WITH p == 0.5 **\n",
    "Classification Accuracy:  42 / 81  =  0.5185185185185185\n",
    "Precision:  41 / 73  =  0.5616438356164384\n",
    "Recall:  41 / 48  =  0.8541666666666666\n",
    "F1:  0.9594748858447488 / 1.415810502283105  =  0.6776859504132232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
