{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model A ALL questions - CoreNLP + TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just the thought of leaving Earth both thrilled and terrified her. Her heart stopped as the trailer-sized shuttle moved forward on the track without making a sound. She took in a deep breath. she said, trying to be brave\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data/Weightless_dataset_train_A.csv\", \"r\", encoding=\"utf-8\")\n",
    "first = True\n",
    "questions = []\n",
    "answers = []\n",
    "grades = []\n",
    "texts = []\n",
    "for line in f:\n",
    "    if first:\n",
    "        first = False\n",
    "        continue\n",
    "    s = line.split(\";\")\n",
    "    questions.append(s[10])\n",
    "    answers.append(s[11])\n",
    "    grades.append(s[14])\n",
    "    texts.append(s[15])\n",
    "    \n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test data (all questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "81\n",
      "81\n",
      "70\n",
      "76\n",
      "67\n",
      "69\n",
      "71\n",
      "69\n",
      "62\n",
      "65\n",
      "68\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data/dataset - fixed.csv\", \"r\", encoding=\"utf-8\")\n",
    "\n",
    "first = True\n",
    "questions_all = []\n",
    "answers_all = []\n",
    "grades_all = []\n",
    "texts_all = []\n",
    "for line in f:\n",
    "    if first:\n",
    "        first = False\n",
    "        continue\n",
    "    s = line.split(\";\")\n",
    "    questions_all.append(s[10])\n",
    "    answers_all.append(s[11])\n",
    "    grades_all.append(s[14])\n",
    "    texts_all.append(s[15])\n",
    "    if s[15] == '1':\n",
    "        print(line)\n",
    "#test_answers = [answers_all[i] for i in range(len(questions_all)) if questions_all[i] == questions[0]]\n",
    "#test_grades = [float(grades_all[i].replace(\",\", \".\")) for i in range(len(questions_all)) if questions_all[i] == questions[0]]\n",
    "\n",
    "## DATA[question_number] -> triples of (queston, grade, answer, text)\n",
    "old = questions_all[0]\n",
    "DATA = []\n",
    "data_tmp = []\n",
    "for i in range(len(questions_all)):\n",
    "    if questions_all[i] == old:\n",
    "        triple = (questions_all[i], grades_all[i], answers_all[i], texts_all[i])\n",
    "        data_tmp.append(triple)\n",
    "    else:\n",
    "        old = questions_all[i]\n",
    "        DATA.append(data_tmp)\n",
    "        data_tmp = []\n",
    "        data_tmp.append((questions_all[i], grades_all[i], texts_all[i]))\n",
    "DATA.append(data_tmp)\n",
    "        \n",
    "print(len(DATA))\n",
    "for i in DATA:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'http://localhost:9000/?properties={\"annotators\": \"openie,coref\", \"outputFormat\": \"json\", \"openie.resolve_coref\": \"true\"}'\n",
    "data = \"Sarah jumped over the table. She got hurt.\"\n",
    "response = requests.post(url, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Sarah  | Relation: jumped over  | Object: table\n",
      "Subject: Sarah  | Relation: got  | Object: hurt\n"
     ]
    }
   ],
   "source": [
    "for s in response.json()[\"sentences\"]:\n",
    "    for i in s[\"openie\"]:\n",
    "        print(\"Subject:\", i[\"subject\"], \" | Relation:\", i[\"relation\"], \" | Object:\", i[\"object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openie_extract(text, resolve_coref=True):\n",
    "    import requests\n",
    "    if resolve_coref:\n",
    "        url = 'http://localhost:9000/?properties={\"annotators\": \"tokenize,ssplit,pos,lemma,openie,coref\", \"outputFormat\": \"json\", \"openie.resolve_coref\": \"true\", \"openie.triple.strict\": \"true\"}'\n",
    "    else:\n",
    "        url = 'http://localhost:9000/?properties={\"annotators\": \"tokenize,ssplit,pos,lemma,openie,coref\", \"outputFormat\": \"json\", \"openie.resolve_coref\": \"false\", \"openie.triple.strict\": \"true\"}'\n",
    "    data = text\n",
    "    response = requests.post(url, data=data)\n",
    "    response.encoding = \"utf-8\"\n",
    "    triples = []\n",
    "    for s in response.json()[\"sentences\"]:\n",
    "        for i in s[\"openie\"]:\n",
    "            #print(\"Subject:\", i[\"subject\"], \" | Relation:\", i[\"relation\"], \" | Object:\", i[\"object\"])\n",
    "            #triples.append((lemmatize([i[\"subject\"]])[0], lemmatize([i[\"relation\"]])[0], lemmatize([i[\"object\"]])[0]))\n",
    "            triples.append((i[\"subject\"], i[\"relation\"], i[\"object\"]))\n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BASE_TRIPLES = []\n",
    "for i in range(len(answers)):\n",
    "    data = answers[i] + \" \" + texts[i]\n",
    "    BASE_TRIPLES.append(openie_extract(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def getTokens(text):\n",
    "    lowered = text.lower()\n",
    "    table = text.maketrans({key: None for key in string.punctuation})\n",
    "    lowered = lowered.translate(table)\n",
    "    return nltk.word_tokenize(lowered)\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmas\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = getTokens(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(lemmas)\n",
    "    #pos_tag = nltk.pos_tag(lemmas)\n",
    "    #print(pos_tag)\n",
    "    #return \" \".join([pt[0] for pt in pos_tag if pt[1] == \"NN\" or pt[1][0:2] == \"VB\" or pt[1] == \"JJ\"])\n",
    "\n",
    "\n",
    "pre_answers = [preprocess(ans) for ans in answers]\n",
    "pre_texts = [preprocess(tex) for tex in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA -> ALL data from csv, DATA[question_number] -> triples of (question, grade, answer, text)\n",
    "\n",
    "answers -> answers for model A (one for each question)\n",
    "\n",
    "texts -> texts for model A (one for each question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  368 / 850\n"
     ]
    }
   ],
   "source": [
    "#weights = vect.transform(test_answers)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "correct = 0\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "all_count = 0\n",
    "\n",
    "#for F1 scoring\n",
    "true_grades = []\n",
    "predicted_grades = []\n",
    "\n",
    "## DATA[question_number] -> triples of (queston, grade, answer, text)\n",
    "for d in range(len(DATA)):\n",
    "    test_answers = [a[2] for a in DATA[d]]\n",
    "    test_grades = [float(a[1]) for a in DATA[d]]\n",
    "    \n",
    "    true_grades += test_grades\n",
    "\n",
    "    vect = TfidfVectorizer() # parameters for tokenization, stopwords can be passed\n",
    "    tfidf = vect.fit_transform([pre_answers[d], pre_texts[d]])\n",
    "    \n",
    "    weights = vect.transform([preprocess(ta) for ta in test_answers])\n",
    "    predict = tfidf * weights.T\n",
    "\n",
    "    #Shiranna feels excited and scared as the shuttle is taking off and it even affects her heart-rate and her temperature.\n",
    "    #test_answers = [\"Excited, scared. It affected her heart rate and temp\"]\n",
    "\n",
    "    \n",
    "    for i in range(len(test_answers)):\n",
    "        all_count += 1 # only for statistics at the end\n",
    "        \n",
    "        test_answer = test_answers[i]\n",
    "        triples = openie_extract(test_answer.encode(\"utf8\"))\n",
    "\n",
    "        p = 0\n",
    "        p_tfidf = 0\n",
    "        p_triples = 0\n",
    "\n",
    "        #if len(triples) < 1:\n",
    "        prediction = max(predict[0,i], predict[1,i])\n",
    "        if prediction > 0.35: #0.5\n",
    "            p_tfidf = 1\n",
    "        elif prediction > 0.2: #0.3\n",
    "            p_tfidf = 0.5\n",
    "        else:\n",
    "            p_tfidf = 0\n",
    "        #else:\n",
    "        for bt in BASE_TRIPLES[d]:\n",
    "            for t in triples:\n",
    "                if t[0] == bt[0] or t[1] == bt[1] or t[2] == bt[2]:\n",
    "                    p_triples += 0.5\n",
    "        p_triples = p_triples*4 / max(len(triples), 1)\n",
    "        prediction = 0\n",
    "        if p_triples >= 1:\n",
    "            p_triples = 1\n",
    "        elif p_triples >= 0.5:\n",
    "            p_triples = 0.5\n",
    "        else:\n",
    "            p_triples = 0\n",
    "\n",
    "        p = (p_triples + p_tfidf) / 2\n",
    "        if p > 0 and p < 1 and p != 0.5:\n",
    "            p = 0.5\n",
    "\n",
    "        predicted_grades.append(p)\n",
    "        #print(\"Predicted:\", p, \" Real:\", test_grades[i], \" --- \", len(triples))\n",
    "        \n",
    "        if p == test_grades[i]:\n",
    "            correct += 1\n",
    "            if p == 1 or p == 0.5:\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        else:\n",
    "            #print(len(triples))\n",
    "            if p == 1 or p == 0.5:\n",
    "                FP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    \n",
    "print(\"Correct: \", correct, \"/\", all_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[texts[0] + answers[0]] 0.3 0.2 -> 38/81 correct\n",
    "\n",
    "[texts[0], answers[0]]  0.3 0.2 -> 42/81 correct \n",
    "\n",
    "CoreNLP openie+coref /w TFIDF -> 32/81 correct\n",
    "\n",
    "CoreNLP openie /w TFIDF ->  40/81 correct\n",
    "\n",
    "CoreNLP openie relative scoring /w TFIDF -> 36/81 correct\n",
    "\n",
    "CoreNLP openie+coref relative scoring /w TFIDF -> 33/81 correct\n",
    "\n",
    "CoreNLP (not strict) openie+coref relative scoring AND TFIDF | AVG -> 43/81 correct\n",
    "\n",
    "CoreNLP openie+coref relative scoring AND TFIDF | AVG -> 40/81 correct\n",
    "\n",
    "CoreNLP openie+coref(with and without) relative scoring AND TFIDF | AVG -> 41/81 correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vsa vprašanja (mikro, makro):  0.4329411764705883 0.3491391579141054\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "tg = [i*2 for i in true_grades]\n",
    "pg = [i*2 for i in predicted_grades]\n",
    "#print(tg)\n",
    "#print(pg)\n",
    "print(\"Vsa vprašanja (mikro, makro): \", f1_score(tg,pg,average=\"micro\"), f1_score(tg,pg,average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score: openIE + coref relative scoring averaged with TFIDF\n",
    "Vsa vprašanja (mikro, makro):  0.4329411764705883 0.3491391579141054  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = TP + TN\n",
    "A = T + FP + FN\n",
    "P = TP/(TP+FP)\n",
    "R = TP/(TP+FN)\n",
    "F1 = 2*P*R/(P+R)\n",
    "print(\"Classification Accuracy: \", T, \"/\", A, \" = \", T/A)\n",
    "print(\"Precision: \", TP, \"/\", TP+FP, \" = \", P)\n",
    "print(\"Recall: \", TP, \"/\", TP+FN, \" = \", TP/(TP+FN))\n",
    "print(\"F1: \", 2*P*R, \"/\", P+R, \" = \", F1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** WITHOUT p == 0.5 **\n",
    "Classification Accuracy:  42 / 81  =  0.5185185185185185\n",
    "Precision:  30 / 54  =  0.5555555555555556\n",
    "Recall:  30 / 45  =  0.6666666666666666\n",
    "F1:  0.7407407407407407 / 1.2222222222222223  =  0.606060606060606\n",
    "\n",
    "** WITH p == 0.5 **\n",
    "Classification Accuracy:  42 / 81  =  0.5185185185185185\n",
    "Precision:  41 / 73  =  0.5616438356164384\n",
    "Recall:  41 / 48  =  0.8541666666666666\n",
    "F1:  0.9594748858447488 / 1.415810502283105  =  0.6776859504132232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
